{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf4b092-1605-4115-90e4-36d0fab4517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# import matplotlib.pyplot as plt\n",
    "from nltk.corpus import twitter_samples, stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "#from wordcloud import WordCloud\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75812cf-23a6-48d6-a474-897d7725c2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\KIIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KIIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n",
    "# Load positive and negative tweets\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84cd35a-aa3b-4327-9331-ff473e9b0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'tweet': positive_tweets + negative_tweets,\n",
    "    'label': [1] * len(positive_tweets) + [0] * len(negative_tweets)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236ac21d-868a-45e6-8928-4900eaf8cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Tweets:\n",
      "                                                tweet  label\n",
      "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...      1\n",
      "1  @Lamb2ja Hey James! How odd :/ Please call our...      1\n",
      "2  @DespiteOfficial we had a listen last night :)...      1\n",
      "3                               @97sides CONGRATS :)      1\n",
      "4  yeaaaah yippppy!!!  my accnt verified rqst has...      1\n",
      "\n",
      "Label Distribution:\n",
      " label\n",
      "1    5000\n",
      "0    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample Tweets:\\n\", data.head())\n",
    "print(\"\\nLabel Distribution:\\n\", data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f8cae4-350a-4a16-9dbe-4dee4d05de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651f5d73-b7f0-4ca7-af8f-aac979a8b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean tweets\n",
    "def preprocess_tweet(tweet):\n",
    "# Remove URLs and mentions\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|@\\S+', '', tweet)  \n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    clean_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.isalpha()]\n",
    "    return ' '.join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abd6542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cleaned = [preprocess_tweet(tweet) for tweet in positive_tweets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "989471b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KIIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d240802-baa3-4ce4-a524-909f56a40f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cleaned = [preprocess_tweet(tweet) for tweet in negative_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "189a5702-c696-48ca-b315-77dccae14de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Tweets Sample:\n",
      "                                                tweet  label\n",
      "0                  top engaged member community week      1\n",
      "1  hey james odd please call contact centre able ...      1\n",
      "2     listen last night bleed amazing track scotland      1\n",
      "3                                           congrats      1\n",
      "4  yeaaah yipppy accnt verified rqst succeed got ...      1\n"
     ]
    }
   ],
   "source": [
    "# Create cleaned dataset\n",
    "cleaned_data = pd.DataFrame({\n",
    "    'tweet': positive_cleaned + negative_cleaned,\n",
    "    'label': [1] * len(positive_cleaned) + [0] * len(negative_cleaned)\n",
    "})\n",
    "\n",
    "print(\"\\nCleaned Tweets Sample:\\n\", cleaned_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352fcc57-e1dc-4d60-9683-0af582b7dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction: TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(cleaned_data['tweet']).toarray()\n",
    "y = cleaned_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52285a72-0167-4178-8560-442b9dd282d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e044fcae-4e71-4ce6-835a-4a05be8f1160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Accuracy: 0.745\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"\\nLogistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d80d5823-ca39-4802-9cac-cddfeabebaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict user input sentiment\n",
    "def predict_sentiment(input_text, model, vectorizer):\n",
    "    cleaned_text = preprocess_tweet(input_text)\n",
    "    text_features = vectorizer.transform([cleaned_text])\n",
    "    prediction = model.predict(text_features)[0]\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "247d5e5b-aae0-4eb9-a97b-4355d6d8fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "# MongoDB Connection\n",
    "client = MongoClient(\"mongodb+srv://ktaunk28:qwerty123@cluster0.dim29.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")  # Local MongoDB instance\n",
    "db = client[\"journaldb\"]  # Replace 'sentiment_db' with your database name\n",
    "collection = db[\"users\"]  # Replace 'input_tweets' with your collection name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "182dadc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6770d7c09138563bc210298c'), 'title': 'string', 'date': datetime.datetime(2024, 12, 29, 5, 1, 52, 457000), 'content': 'string', 'sentiment': '', '_class': 'net.khushtaunk.journalApp.Entity.journalEntry'}\n",
      "{'_id': ObjectId('67715b04124a453fbd2c0573'), 'title': 'lets edit this', 'date': datetime.datetime(2024, 12, 29, 14, 21, 56, 900000), 'content': 'okkk edited', 'sentiment': '', '_class': 'net.khushtaunk.journalApp.Entity.journalEntry'}\n",
      "{'_id': ObjectId('67715d47124a453fbd2c0574'), 'title': 'hello', 'date': datetime.datetime(2024, 12, 29, 14, 31, 35, 317000), 'content': 'helloooo', 'sentiment': '', '_class': 'net.khushtaunk.journalApp.Entity.journalEntry'}\n",
      "{'_id': ObjectId('67717576239af27b2cd4f61c'), 'title': 'just test', 'date': datetime.datetime(2024, 12, 29, 16, 14, 46, 450000), 'content': 'doing this for teting', 'sentiment': '', '_class': 'net.khushtaunk.journalApp.Entity.journalEntry'}\n",
      "{'_id': ObjectId('6776b37a058cba56ef8811e6'), 'title': 'hey this is khush', 'date': datetime.datetime(2025, 1, 2, 15, 40, 42, 399000), 'content': 'am just writing this to make me happy', 'sentiment': '', '_class': 'net.khushtaunk.journalApp.Entity.journalEntry'}\n",
      "Sentiment analysis results saved to MongoDB.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb+srv://ktaunk28:qwerty123@cluster0.dim29.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")  # Replace with your MongoDB URI if needed\n",
    "db = client['journaldb']  # Connect to the journaldb database\n",
    "users_collection = db['users']  # Access the users collection\n",
    "journal_entries_collection = db['journal_Entries']  # Access the journal_Entries collection\n",
    "\n",
    "# Fetch a specific user by ID\n",
    "user_id = ObjectId(\"67700c6266604f272107a387\")  # Replace with the actual user ObjectId\n",
    "user_document = users_collection.find_one({\"_id\": user_id})\n",
    "\n",
    "# Ensure user exists and has journal entries\n",
    "if user_document and \"journalEntries\" in user_document:\n",
    "    journal_entries_refs = user_document[\"journalEntries\"]  # Array of DBRef objects\n",
    "\n",
    "    # Fetch the journal entries from the referenced collection\n",
    "    journal_entries = []\n",
    "    for ref in journal_entries_refs:\n",
    "        entry_id = ref.id  # Get the ObjectId of the journal entry\n",
    "        entry_document = journal_entries_collection.find_one({\"_id\": entry_id})\n",
    "        if entry_document:\n",
    "            journal_entries.append(entry_document)\n",
    "\n",
    "    # Example: Display fetched journal entries\n",
    "    for entry in journal_entries:\n",
    "        print(entry)\n",
    "\n",
    "    # Process and analyze each journal entry\n",
    "    def analyze_journal_entry(entry_text):\n",
    "        cleaned_entry = preprocess_tweet(entry_text)  # Assuming a preprocess_tweet() function\n",
    "        features = vectorizer.transform([cleaned_entry])  # Vectorize the text\n",
    "        prediction = lr_model.predict(features)[0]  # Predict sentiment\n",
    "        return \"Positive\" if prediction == 1 else \"Negative\"\n",
    "\n",
    "    # Perform sentiment analysis\n",
    "    analysis_results = []\n",
    "    for entry in journal_entries:\n",
    "        if \"text\" in entry:  # Assuming each journal entry has a \"text\" field\n",
    "            sentiment = analyze_journal_entry(entry[\"text\"])\n",
    "            analysis_results.append({\"entry_id\": entry[\"_id\"], \"sentiment\": sentiment})\n",
    "\n",
    "    # Save the analysis results back to the user's document\n",
    "    users_collection.update_one(\n",
    "        {\"_id\": user_id},\n",
    "        {\"$set\": {\"journal_Analysis\": analysis_results}}  # Add a new field for analysis results\n",
    "    )\n",
    "    print(\"Sentiment analysis results saved to MongoDB.\")\n",
    "else:\n",
    "    print(\"User not found or no journal entries available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fa4653d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Results: [{'entry_id': ObjectId('6770d7c09138563bc210298c'), 'content': 'string', 'sentiment': 'Negative'}, {'entry_id': ObjectId('67715b04124a453fbd2c0573'), 'content': 'okkk edited', 'sentiment': 'Negative'}, {'entry_id': ObjectId('67715d47124a453fbd2c0574'), 'content': 'helloooo', 'sentiment': 'Negative'}, {'entry_id': ObjectId('67717576239af27b2cd4f61c'), 'content': 'doing this for teting', 'sentiment': 'Negative'}, {'entry_id': ObjectId('6776b37a058cba56ef8811e6'), 'content': 'am just writing this to make me happy', 'sentiment': 'Positive'}]\n"
     ]
    }
   ],
   "source": [
    "# Apply analysis to the content field of all journal entries\n",
    "results = []\n",
    "\n",
    "# Loop through journal entries and analyze their 'content' fields\n",
    "for entry in journal_entries:\n",
    "    if \"content\" in entry:  # Ensure the 'content' field exists\n",
    "        sentiment = analyze_journal_entry(entry[\"content\"])  # Pass only the 'content' field\n",
    "        results.append({\n",
    "            \"entry_id\": entry[\"_id\"],  # Include the unique ID of the journal entry\n",
    "            \"content\": entry[\"content\"],  # Include the original content for reference\n",
    "            \"sentiment\": sentiment       # Include the sentiment analysis result\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Entry with ID {entry['_id']} has no 'content' field.\")  # Log missing 'content' fields\n",
    "\n",
    "print(\"Analysis Results:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61be0e81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f811c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the journal entries with sentiment analysis results\n",
    "for result in results:\n",
    "    db[\"journal_Entries\"].update_one(\n",
    "        {\"_id\": result[\"entry_id\"]},\n",
    "        {\"$set\": {\"sentiment\": result[\"sentiment\"]}}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890425e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e2b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc296d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95ef56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ef1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f9827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe14884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd3fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172bf06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b78c9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e20c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413bbbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a5587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340c407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6588af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1fb952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf270fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f625ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac4045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354af88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a15cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef05209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f9ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51327afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f7d1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199a40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3e7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25cc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d8d06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075c973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d52bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9ad87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a792f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb624a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2adef71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff3d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9020f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5772c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb14c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e71348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d627f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66498cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf772d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195cf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadc731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7add44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb48e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587feb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720d648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251105ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5ffc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e7b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75374e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d73ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a367e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd9218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb4c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078227db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b85206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff594327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fcb164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d2403e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995adac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1e347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd30bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e9148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e010cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe93ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc7670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1591d2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da0ff71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e1788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18d490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57c253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92586d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb660208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501edb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636304a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684f7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a15857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19285a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ee54c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac132ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ee1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3b8a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a4ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11539040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821a3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08018b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409411fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1130f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea452162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a70802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b070437d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3dd82e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
